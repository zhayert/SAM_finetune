train:
  experiment_name: 'semantic_sam'

  # Model
  model:
    sam_name: 'sem_sam'
    params:
      # Fix the a part of parameters in SAM
      fix_image_encoder: True
      fix_prompt_encoder: True
      fix_mask_decoder: False
      ckpt_path: '../../ckpt/sam_ckpt/sam_vit_b_01ec64.pth'
      class_num: 21 # 20 + 1
      model_type: 'vit_b'    # type should be in [vit_h, vit_b, vit_l, default]

  # Dataset
  dataset:
    name: 'torch_voc_sem'
    params:
      root: '../../dataset'
      year: '2012'
      image_set: 'train'
    transforms:
      resize:
        params:
          size: [1024, 1024]
      to_tensor:
        params: ~
    target_transforms:
      resize:
        params:
          size: [1024, 1024]

  # Losses
  losses:
    ce:
      weight: 0.5
      params:  # ~ means None type, the initial params of loss could be identified here
        ignore_index: 255
      label_one_hot: False

  # Optimizer
  opt_params:
#    lr_default: 1e-3
    lr_default: 0.001
#    wd_default: 1e-4
    wd_default: 0.0001
    momentum: 0.9
    lr_list:  [ 0.01, ]
    group_keys: [ [ 'mask_adapter.decoder_head.output_hypernetworks_mlps', ], ]
    wd_list:  [ 0.0, ]
  opt_name: 'sgd' # 'sgd'
  scheduler_name: 'cosine'

  # Runner
  max_iter: 100000
  log_iter: 50
  eval_iter: 200
  runner_name: 'sem_runner'
  # Dataloader
#  bs: 8 # 8
  bs: 1
  num_workers: 2
#  num_workers: 0
  drop_last: True
  # Logger
  use_tensorboard: True
  tensorboard_folder: './experiment/tensorboard'
  log_folder: './experiment/log'
  model_folder: './experiment/model'

val:
  # Dataset
  dataset:
    name: 'torch_voc_sem'
    params:
      root: '../../dataset'
      year: '2012'
      image_set: 'train'
    transforms:
      resize:
        params:
          size: [1024, 1024]
      to_tensor:
        params: ~
    target_transforms:
      resize:
        params:
          size: [1024, 1024]

#  bs: 8
  bs: 1
#  num_workers:
  num_workers: 2
  drop_last: True


test:
  need_test: False

